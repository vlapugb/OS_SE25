# Select/poll/epoll — мотивация и принципы работы

## 1. Контекст: ввод-вывод и блокирующие операции

Во многих задачах (сетевые серверы, чаты, прокси, мониторинг) программа должна:
- одновременно работать с **множеством источников ввода-вывода** (сокеты, pipe’ы, файлы);
- **своевременно** реагировать на появление данных или возможности записи;
- не создавать по потоку/процессу на каждый сокет.

### 1.1. Блокирующий ввод-вывод

Системные вызовы:
- `read()`, `recv()`, `accept()`, `connect()` и др.

по умолчанию **блокируют** поток, пока операция не может быть выполнена:
- нет данных → `read()` ждёт;
- нет входящих соединений → `accept()` ждёт.

Это:
- удобно для простых программ;
- плохо масштабируется при большом числе соединений.

---

## 2. Наивные решения и мотивация мультиплексирования

### 2.1. Один поток/процесс на соединение

Для каждого клиента:
- создаётся отдельный поток/процесс, который блокируется на `read()`/`recv()`.

Недостатки:
- большая нагрузка на планировщик ОС (переключение контекстов);
- расход памяти (стек, структуры ядра);
- сложная синхронизация;
- плохая масштабируемость (сотни/тысячи подключений).

### 2.2. Неблокирующий I/O + «крутилка» (busy waiting)

Сокеты переводятся в `O_NONBLOCK` и постоянно опрашиваются в цикле:

```c
for (;;) {
    for (каждый fd) {
        read(fd, ...); // либо данные, либо EAGAIN
    }
}
```

Недостатки:
- постоянная загрузка CPU «вхолостую»;
- сложность логики;
- всё равно неэффективно.

### 2.3. Что хотелось бы

Нужен механизм, который позволяет **ядру**:
- следить за множеством дескрипторов;
- «будить» процесс только тогда, когда:
  - на каком-то дескрипторе появились данные для чтения;
  - можно писать, не блокируясь;
  - произошла ошибка или закрытие;
  - истёк тайм-аут.

Эту идею реализуют:
- `select()`;
- `poll()`;
- и более современный интерфейс **`epoll`** в Linux.

---

## 3. select(): принцип работы

### 3.1. Общая идея

`select()` — классический механизм **мультиплексированного ввода-вывода**.

Процесс передаёт ядру:
- три набора дескрипторов:
  - `readfds` — интересует **готовность к чтению**;
  - `writefds` — интересует **готовность к записи**;
  - `exceptfds` — интересуют **исключения** (out-of-band и т.п.);
- и тайм-аут.

Ядро:
- блокирует процесс;
- следит за состоянием дескрипторов;
- как только хотя бы один дескриптор «готов» — `select()` возвращает.

### 3.2. Прототип

```c
int select(int nfds,
           fd_set *readfds,
           fd_set *writefds,
           fd_set *exceptfds,
           struct timeval *timeout);
```

- `nfds` — **максимальный номер дескриптора + 1**;
- `fd_set` — битовая маска дескрипторов;
- `timeout`:
  - `NULL` — ждать бесконечно;
  - `{0, 0}` — не ждать (опрос);
  - другое значение — ограниченное ожидание.

Возвращаемое значение:
- `> 0` — число готовых дескрипторов;
- `0` — истёк тайм-аут;
- `< 0` — ошибка.

### 3.3. Работа с fd_set

Макросы:

```c
FD_ZERO(&set);     // очистить множество
FD_SET(fd, &set);  // добавить дескриптор
FD_CLR(fd, &set);  // удалить дескриптор
FD_ISSET(fd,&set); // проверка готовности
```

Последовательность:
1. Очистить множества (`FD_ZERO`).
2. Добавить нужные дескрипторы (`FD_SET`).
3. Вызвать `select()`.
4. После возврата:
   - `fd_set` изменён ядром: в нём только **готовые** дескрипторы.
   - проверяем каждый дескриптор через `FD_ISSET`.

Важно:
- перед **каждым** новым вызовом `select()` нужно заново формировать `fd_set`.

### 3.4. Ограничения select()

1. **FD_SETSIZE**  
   - максимум дескрипторов, которые можно контролировать (обычно 1024);
   - ограничивает масштабируемость.

2. **Линейный перебор**  
   - ядро должно проверять все дескрипторы до `nfds-1`;
   - сложность `O(N)`.

3. **Неудобство пересоздания наборов**  
   - после каждого `select()` нужно снова заполнять `fd_set`.

---

## 4. poll(): мотивация и устройство

### 4.1. Зачем нужен poll()

`poll()` был создан для устранения части недостатков `select()`:
- убрать жёсткий лимит `FD_SETSIZE`;
- заменить битовые маски на более удобные структуры;
- дать гибкий интерфейс для динамических наборов дескрипторов.

### 4.2. Прототип

```c
int poll(struct pollfd *fds, nfds_t nfds, int timeout);
```

Где:

```c
struct pollfd {
    int   fd;       // дескриптор
    short events;   // интересующие события
    short revents;  // реально произошедшие события (заполняет ядро)
};
```

- `events` — маска интересующих событий, например:
  - `POLLIN` — готовность к чтению;
  - `POLLOUT` — готовность к записи;
  - `POLLERR`, `POLLHUP`, `POLLPRI` и др.
- `revents` — маска **фактических** событий.

`timeout`:
- `-1` — ждать бесконечно;
- `0` — не ждать;
- >0 — миллисекунды ожидания.

Возвращаемое значение:
- `> 0` — количество дескрипторов с событиями;
- `0` — истёк тайм-аут;
- `< 0` — ошибка.

### 4.3. Пример использования poll()

```c
struct pollfd fds[2];

fds[0].fd = listen_sock;
fds[0].events = POLLIN;      // ждём новые подключения

fds[1].fd = client_sock;
fds[1].events = POLLIN|POLLOUT; // ждём и чтение, и запись

int n = poll(fds, 2, 1000);  // ждать до 1 секунды
if (n > 0) {
    if (fds[0].revents & POLLIN) {
        // есть новое подключение
    }
    if (fds[1].revents & POLLIN) {
        // есть данные от клиента
    }
    if (fds[1].revents & POLLOUT) {
        // можно писать клиенту
    }
}
```

### 4.4. Преимущества и недостатки poll()

**Плюсы:**
- нет жёсткого ограничение типа `FD_SETSIZE`;
- дескрипторы хранятся в обычном массиве;
- удобно добавлять/удалять/изменять элементы.

**Минусы:**
- всё равно требуется **линейный перебор** массива дескрипторов в ядре → `O(N)`;
- при очень большом числе соединений становится неэффективным.

---

## 5. epoll: мотивация и базовые идеи

### 5.1. Почему недостаточно select/poll

При тысячах и десятках тысяч соединений:
- `select()` и `poll()` становятся «узким местом»:
  - каждый вызов требует **передать в ядро полный список дескрипторов**;
  - ядро каждый раз **обходит весь список** (`O(N)`), даже если событие на 1–2 сокетах;
- это даёт большой overhead при высоконагруженных серверах.

Linux ввёл **epoll**:
- специализированный интерфейс для **масштабируемого** мультиплексирования ввода-вывода;
- эффективен при большом числе файловых дескрипторов (тысячи и более).

### 5.2. Ключевые отличия epoll

1. **Разделение регистрации и ожидания:**
   - дескрипторы **один раз регистрируются** в epoll-объекте;
   - дальше при ожидании событий **не нужно** каждый раз передавать весь набор.

2. **Модель «готовых» дескрипторов:**
   - ядро само поддерживает **множество готовых дескрипторов**;
   - при вызове `epoll_wait()` возвращается только список тех, где что-то произошло.

3. **Лучшая масштабируемость:**
   - при правильной реализации — близко к `O(1)` (зависит от числа активных событий, а не от общего числа дескрипторов).

---

## 6. Интерфейс epoll

epoll — Linux-специфичный API. Основные функции:

- `epoll_create1()`
- `epoll_ctl()`
- `epoll_wait()`

### 6.1. Создание epoll-объекта: epoll_create1()

```c
int epfd = epoll_create1(int flags);
```

- `flags`:
  - обычно `0` или `EPOLL_CLOEXEC`;
- возвращает дескриптор epoll-объекта.

Этот дескриптор:
- используется в последующих вызовах;
- по сути представляет собой «таблицу отслеживаемых дескрипторов» внутри ядра.

### 6.2. Регистрация и изменение дескрипторов: epoll_ctl()

```c
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
```

- `epfd` — дескриптор epoll;
- `op` — операция:
  - `EPOLL_CTL_ADD` — добавить fd;
  - `EPOLL_CTL_MOD` — изменить маску событий;
  - `EPOLL_CTL_DEL` — удалить fd;
- `fd` — отслеживаемый файловый дескриптор;
- `event` — указывает, какие события интересуют, и пользовательские данные.

Структура `epoll_event`:

```c
struct epoll_event {
    uint32_t events; /* EPOLLIN, EPOLLOUT, EPOLLERR, ... */
    epoll_data_t data;
};

typedef union epoll_data {
    void        *ptr;
    int          fd;
    uint32_t     u32;
    uint64_t     u64;
} epoll_data_t;
```

- Поле `data` удобно для хранения:
  - либо самого `fd`,
  - либо указателя на структуру с информацией о соединении.

### 6.3. Ожидание событий: epoll_wait()

```c
int epoll_wait(int epfd,
               struct epoll_event *events,
               int maxevents,
               int timeout);
```

Параметры:
- `events` — массив, в который ядро запишет события;
- `maxevents` — размер массива;
- `timeout` — ожидание в миллисекундах:
  - `-1` — ждать бесконечно;
  - `0` — не ждать.

Возвращаемое значение:
- `> 0` — число событий, записанных в `events`;
- `0` — истёк тайм-аут;
- `< 0` — ошибка.

### 6.4. Типовые флаги событий в epoll

- `EPOLLIN` — данные доступны для чтения;
- `EPOLLOUT` — дескриптор готов для записи;
- `EPOLLERR` — ошибка;
- `EPOLLHUP` — «обрыв» (закрытие другого конца);
- `EPOLLRDHUP` — удалённая сторона закрыла половину соединения.

Дополнительно:
- `EPOLLET` — edge-triggered режим (см. ниже);
- `EPOLLONESHOT` — одноразовое событие, после которого нужно заново регистрировать интерес.

---

## 7. Уровневый и фронтовый (edge) режим в epoll

### 7.1. Level-triggered (по уровню)

По умолчанию epoll, как `select/poll`, работает в **уровневом режиме**:

- если сокет готов к чтению (есть данные),
- то на каждом вызове `epoll_wait()` будет событие `EPOLLIN`,
- пока данные не будут прочитаны.

### 7.2. Edge-triggered (по фронту): EPOLLET

Если задать флаг `EPOLLET`:

- событие генерируется **только в момент изменения состояния**, например:
  - данные появились в буфере;
  - сокет стал доступен для записи;
- если не вычитать все данные, можно больше не получить уведомления.

Плюсы:
- уменьшает число повторяющихся событий;
- снижает overhead при большом количестве активных дескрипторов.

Минусы:
- более сложная логика:
  - нужно **читать/писать до упора**, пока не будет `EAGAIN`;
  - иначе можно «пропустить» событие.

---

## 8. Типовая схема сервера на epoll

1. Создаём слушающий сокет `listen_sock` (через `socket + bind + listen`).
2. Создаём epoll-объект:
   ```c
   int epfd = epoll_create1(0);
   ```
3. Регистрируем слушающий сокет:
   ```c
   struct epoll_event ev;
   ev.events = EPOLLIN;
   ev.data.fd = listen_sock;
   epoll_ctl(epfd, EPOLL_CTL_ADD, listen_sock, &ev);
   ```
4. Входим в цикл:
   ```c
   struct epoll_event events[MAX_EVENTS];

   for (;;) {
       int n = epoll_wait(epfd, events, MAX_EVENTS, -1);
       for (int i = 0; i < n; ++i) {
           int fd = events[i].data.fd;
           uint32_t evs = events[i].events;

           if (fd == listen_sock && (evs & EPOLLIN)) {
               // новое входящее соединение
               int client = accept(listen_sock, ...);
               struct epoll_event cev;
               cev.events = EPOLLIN;
               cev.data.fd = client;
               epoll_ctl(epfd, EPOLL_CTL_ADD, client, &cev);
           } else if (evs & EPOLLIN) {
               // данные от клиента fd
               // читаем, обрабатываем, при закрытии — EPOLL_CTL_DEL + close(fd)
           }
           // при необходимости проверяем EPOLLOUT, EPOLLERR, EPOLLHUP и т.п.
       }
   }
   ```

Преимущество:
- множество зарегистрированных дескрипторов может быть очень большим (десятки тысяч);
- `epoll_wait()` возвращает **только те**, где есть события;
- не нужно каждый раз передавать ядру массив всех сокетов.

---

## 9. Сравнение select, poll и epoll

### 9.1. Концептуальное сравнение

| Характеристика                      | select                        | poll                          | epoll (Linux)                                |
|------------------------------------|-------------------------------|-------------------------------|----------------------------------------------|
| Представление дескрипторов         | `fd_set` (битовые маски)      | массив `struct pollfd`        | внутренний epoll-объект + массив событий     |
| Регистрация дескрипторов           | каждый раз заново             | каждый раз заново             | один раз через `epoll_ctl`                   |
| Лимит по числу дескрипторов        | есть (`FD_SETSIZE`)           | нет жёсткого лимита           | ограничен только ресурсами                   |
| Сложность обработки в ядре         | `O(N)` по диапазону [0..nfds) | `O(N)` по массиву             | стремится к `O(число_активных_событий)`      |
| Тайм-аут                           | `timeval` (сек + мкс)         | миллисекунды (int)            | миллисекунды (int)                           |
| Тип механизмов                     | level-triggered               | level-triggered               | level-triggered и **edge-triggered** (EPOLLET) |
| Портируемость                      | POSIX, есть везде             | POSIX, широко доступен        | только Linux                                  |
| Удобство для небольшого числа FD   | просто, привычно              | удобно, более гибко           | возможен, но избыточен                       |
| Производительность при тысячах FD  | низкая                        | низкая                        | высокая (типичный выбор для high-load)       |

### 9.2. Идеологические выводы

- `select()`:
  - исторически первый, «учебный»;
  - разумен для простых программ и небольшого числа дескрипторов;
  - ограничен FD_SETSIZE.

- `poll()`:
  - более универсален и гибок;
  - избавляет от лимита FD_SETSIZE;
  - но по сложности всё тот же `O(N)`.

- `epoll`:
  - ориентирован на **высоконагруженные Linux-сервера**;
  - разделяет этапы:
    - **регистрация** (`epoll_ctl`);
    - **ожидание** (`epoll_wait`);
  - при большом количестве дескрипторов даёт значительный выигрыш;
  - поддерживает edge-triggered режим, удобный для высокопроизводительных приложений (но требует аккуратно писать код).

---

## 10. Краткий конспект (как отвечать на экзамене)

1. **Мотивация select/poll/epoll**:
   - нужен механизм, позволяющий **одному потоку** ждать события на **множестве** дескрипторов;
   - блокирующий I/O на одном дескрипторе — недопустим при множестве клиентов;
   - `select` и `poll` решают эту задачу, но плохо масштабируются;
   - `epoll` решает проблему масштабируемости на Linux.

2. **select**:
   - работает с `fd_set`, ограничен `FD_SETSIZE`;
   - при каждом вызове нужно заново формировать множества;
   - ядро проверяет все дескрипторы до `nfds` → `O(N)`;
   - level-triggered.

3. **poll**:
   - массив `pollfd`, нет жёсткого лимита по дескрипторам;
   - события в `revents`;
   - по-прежнему `O(N)`;
   - также level-triggered.

4. **epoll**:
   - Linux-специфичный;
   - разделяет:
     - регистрацию дескрипторов (`epoll_ctl`);
     - ожидание событий (`epoll_wait`);
   - не нужно каждый раз передавать полный список;
   - ядро возвращает только активные дескрипторы;
   - масштабируется лучше (`O(кол-во_событий)`);
   - поддерживает level-triggered и edge-triggered (EPOLLET).

5. **Сравнение**:
   - select/poll хороши для небольших программ и как учебные примеры;
   - epoll — выбор для высоконагруженных сетевых серверов под Linux.

Этот конспект можно использовать как развёрнутый ответ на экзаменационный билет  
**«select/poll: мотивация и принципы работы»** с дополнением **про epoll и сравнением всех трёх механизмов**.
